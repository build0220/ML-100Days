{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間\n",
    "將你的結果存成 csv, 上傳你的第一份 Kaggle 成績\n",
    "\n",
    "Hints: https://stackoverflow.com/questions/16923281/pandas-writing-dataframe-to-csv-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 需要的套件\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 之前做過的處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定 data_path\n",
    "dir_data = './data/'\n",
    "f_app_train = os.path.join(dir_data, 'application_train.csv')\n",
    "f_app_test = os.path.join(dir_data, 'application_test.csv')\n",
    "\n",
    "app_train = pd.read_csv(f_app_train)\n",
    "app_test = pd.read_csv(f_app_test)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app_train[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(app_train[col])\n",
    "            # Transform both training and testing data\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            app_test[col] = le.transform(app_test[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "app_train = pd.get_dummies(app_train)\n",
    "app_test = pd.get_dummies(app_test)\n",
    "\n",
    "# Create an anomalous flag column\n",
    "app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "# also apply to testing dataset\n",
    "app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "# absolute the value of DAYS_BIRTH\n",
    "app_train['DAYS_BIRTH'] = abs(app_train['DAYS_BIRTH'])\n",
    "app_test['DAYS_BIRTH'] = abs(app_test['DAYS_BIRTH'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 做好前處理\n",
    "開始擬合模型之前，我們要確保 training & testing data 的欄位數量一致，原因是因為 One hot encoding 會製造多的欄位，有些類別出現在 training data 而沒有出現 testing data 中，我們就要把這些多餘的欄位去除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = app_train['TARGET']\n",
    "\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "\n",
    "# Add the target back in\n",
    "app_train['TARGET'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 240)\n",
      "Testing data shape:  (48744, 240)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "\n",
    "# Drop the target from the training data\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(labels = ['TARGET'], axis=1)\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "    \n",
    "# Feature names\n",
    "features = list(train.columns)\n",
    "\n",
    "# Copy of the testing data\n",
    "test = app_test.copy()\n",
    "\n",
    "# Median imputation of missing values\n",
    "imputer = Imputer(strategy = 'median')\n",
    "\n",
    "# Scale each feature to 0-1\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "# Fit on the training data\n",
    "imputer.fit(train)\n",
    "\n",
    "# Transform both training and testing data\n",
    "train = imputer.transform(train)\n",
    "test = imputer.transform(app_test)\n",
    "\n",
    "# Repeat with the scaler\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "print('Training data shape: ', train.shape)\n",
    "print('Testing data shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Make the model with the specified regularization parameter\n",
    "log_reg = LogisticRegression(C = 0.0001)\n",
    "\n",
    "# Train on the training data\n",
    "log_reg.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型 fit 好以後，就可以用來預測 testing data 中的客戶違約遲繳貸款的機率咯! (記得要用 predict_proba 才會輸出機率)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06505115, 0.12640086, 0.08123883, ..., 0.05702381, 0.07413523,\n",
       "       0.08983229])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "# Make sure to select the second column only\n",
    "log_reg_pred = log_reg.predict_proba(test)[:, 1]\n",
    "log_reg_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 儲存預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.065051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.126401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.081239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.061509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.128308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR    TARGET\n",
       "0      100001  0.065051\n",
       "1      100005  0.126401\n",
       "2      100013  0.081239\n",
       "3      100028  0.061509\n",
       "4      100038  0.128308"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submission dataframe\n",
    "submit = app_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = log_reg_pred\n",
    "\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submit.to_csv('creditRiskPredict.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.065051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.126401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.081239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.061509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.128308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100042</td>\n",
       "      <td>0.055894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100057</td>\n",
       "      <td>0.083035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100065</td>\n",
       "      <td>0.125470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100066</td>\n",
       "      <td>0.050359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100067</td>\n",
       "      <td>0.103295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100074</td>\n",
       "      <td>0.063246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100090</td>\n",
       "      <td>0.115127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100091</td>\n",
       "      <td>0.117158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100092</td>\n",
       "      <td>0.098101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100106</td>\n",
       "      <td>0.155821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100107</td>\n",
       "      <td>0.111813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100109</td>\n",
       "      <td>0.098570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100117</td>\n",
       "      <td>0.076216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100128</td>\n",
       "      <td>0.073494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100141</td>\n",
       "      <td>0.087928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100150</td>\n",
       "      <td>0.075497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100168</td>\n",
       "      <td>0.064995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100169</td>\n",
       "      <td>0.044325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100170</td>\n",
       "      <td>0.086903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100171</td>\n",
       "      <td>0.099828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100172</td>\n",
       "      <td>0.121537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100184</td>\n",
       "      <td>0.073917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100187</td>\n",
       "      <td>0.061739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100212</td>\n",
       "      <td>0.085807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100222</td>\n",
       "      <td>0.084763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48714</th>\n",
       "      <td>455963</td>\n",
       "      <td>0.087939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48715</th>\n",
       "      <td>455965</td>\n",
       "      <td>0.085623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48716</th>\n",
       "      <td>456007</td>\n",
       "      <td>0.133974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48717</th>\n",
       "      <td>456008</td>\n",
       "      <td>0.066537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48718</th>\n",
       "      <td>456009</td>\n",
       "      <td>0.077020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48719</th>\n",
       "      <td>456010</td>\n",
       "      <td>0.077867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48720</th>\n",
       "      <td>456011</td>\n",
       "      <td>0.061562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48721</th>\n",
       "      <td>456013</td>\n",
       "      <td>0.095848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48722</th>\n",
       "      <td>456028</td>\n",
       "      <td>0.124448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48723</th>\n",
       "      <td>456058</td>\n",
       "      <td>0.088149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48724</th>\n",
       "      <td>456111</td>\n",
       "      <td>0.103099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48725</th>\n",
       "      <td>456114</td>\n",
       "      <td>0.094245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48726</th>\n",
       "      <td>456115</td>\n",
       "      <td>0.095882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48727</th>\n",
       "      <td>456116</td>\n",
       "      <td>0.069321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48728</th>\n",
       "      <td>456119</td>\n",
       "      <td>0.059839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48729</th>\n",
       "      <td>456120</td>\n",
       "      <td>0.102240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48730</th>\n",
       "      <td>456122</td>\n",
       "      <td>0.116229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48731</th>\n",
       "      <td>456123</td>\n",
       "      <td>0.046316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48732</th>\n",
       "      <td>456166</td>\n",
       "      <td>0.089938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48733</th>\n",
       "      <td>456167</td>\n",
       "      <td>0.068266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48734</th>\n",
       "      <td>456168</td>\n",
       "      <td>0.094200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48735</th>\n",
       "      <td>456169</td>\n",
       "      <td>0.056179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48736</th>\n",
       "      <td>456170</td>\n",
       "      <td>0.052039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48737</th>\n",
       "      <td>456189</td>\n",
       "      <td>0.085418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48738</th>\n",
       "      <td>456202</td>\n",
       "      <td>0.091333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48739</th>\n",
       "      <td>456221</td>\n",
       "      <td>0.082729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48740</th>\n",
       "      <td>456222</td>\n",
       "      <td>0.085411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48741</th>\n",
       "      <td>456223</td>\n",
       "      <td>0.057024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48742</th>\n",
       "      <td>456224</td>\n",
       "      <td>0.074135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48743</th>\n",
       "      <td>456250</td>\n",
       "      <td>0.089832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SK_ID_CURR    TARGET\n",
       "0          100001  0.065051\n",
       "1          100005  0.126401\n",
       "2          100013  0.081239\n",
       "3          100028  0.061509\n",
       "4          100038  0.128308\n",
       "5          100042  0.055894\n",
       "6          100057  0.083035\n",
       "7          100065  0.125470\n",
       "8          100066  0.050359\n",
       "9          100067  0.103295\n",
       "10         100074  0.063246\n",
       "11         100090  0.115127\n",
       "12         100091  0.117158\n",
       "13         100092  0.098101\n",
       "14         100106  0.155821\n",
       "15         100107  0.111813\n",
       "16         100109  0.098570\n",
       "17         100117  0.076216\n",
       "18         100128  0.073494\n",
       "19         100141  0.087928\n",
       "20         100150  0.075497\n",
       "21         100168  0.064995\n",
       "22         100169  0.044325\n",
       "23         100170  0.086903\n",
       "24         100171  0.099828\n",
       "25         100172  0.121537\n",
       "26         100184  0.073917\n",
       "27         100187  0.061739\n",
       "28         100212  0.085807\n",
       "29         100222  0.084763\n",
       "...           ...       ...\n",
       "48714      455963  0.087939\n",
       "48715      455965  0.085623\n",
       "48716      456007  0.133974\n",
       "48717      456008  0.066537\n",
       "48718      456009  0.077020\n",
       "48719      456010  0.077867\n",
       "48720      456011  0.061562\n",
       "48721      456013  0.095848\n",
       "48722      456028  0.124448\n",
       "48723      456058  0.088149\n",
       "48724      456111  0.103099\n",
       "48725      456114  0.094245\n",
       "48726      456115  0.095882\n",
       "48727      456116  0.069321\n",
       "48728      456119  0.059839\n",
       "48729      456120  0.102240\n",
       "48730      456122  0.116229\n",
       "48731      456123  0.046316\n",
       "48732      456166  0.089938\n",
       "48733      456167  0.068266\n",
       "48734      456168  0.094200\n",
       "48735      456169  0.056179\n",
       "48736      456170  0.052039\n",
       "48737      456189  0.085418\n",
       "48738      456202  0.091333\n",
       "48739      456221  0.082729\n",
       "48740      456222  0.085411\n",
       "48741      456223  0.057024\n",
       "48742      456224  0.074135\n",
       "48743      456250  0.089832\n",
       "\n",
       "[48744 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
